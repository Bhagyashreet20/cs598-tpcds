{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''script to create the final fine-tuning dataset for fine-tuning the model with the augmented tpcds data\n",
    "each entry has input,output,id,text. attribute text is the input for the fine-tuning process.'''\n",
    "import os \n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create modified dataset including prompt for fine-tuning \n",
    "import json\n",
    "file_path = \"/workspace/data/finetuning/dataset/sqlize-dataset.json\"\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    sqlize_data = json.load(file)\n",
    "\n",
    "print(len(sqlize_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_prompt=f'''\n",
    "[SYSTEM]:\"You are an expert Text-to-SQL generator assistant. Your goal is to provide correct SQL queries to the given text description. Your output only contains the SQL code. No explanation or introductory sentences surrounding the SQL response is needed. You are given schema information. Here is the schema information: \n",
    "{\"{schema_info}\"}. Here are the 5 critical rules for the interactions you must abide: <rules> 1. Do not wrap the generated SQL code within SQL code markdown format. Also, do not include the SQL keyword in the beginning of the response. 2. If I don't tell you to find the limited set of results, limit to 100. 3. Only use table and columns from the list provided 4. When performing aliasing, make sure to refer the aliased tables as alias.column_name and not as alias_column_name. 5. For US state names, use abbreviated forms. For example, for South Dakota state, use SD.</rules> \n",
    "\n",
    "\"Here is the user question:\"[/SYSTEM]\n",
    "[HUMAN]:{\"{user_input}\"}[/HUMAN]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_data=[]\n",
    "for queryIdx in range(len(sqlize_data)):\n",
    "    user_input=finetuned_prompt.format(schema_info=sqlize_data[queryIdx][\"schema\"],user_input=sqlize_data[queryIdx][\"nlq\"])\n",
    "    output=sqlize_data[queryIdx][\"sql\"]\n",
    "    finetuned_data.append({\n",
    "        \"id\":sqlize_data[queryIdx][\"id\"],\n",
    "        \"input\":user_input,\n",
    "        \"output\":output,\n",
    "        \"text\": f'''\\n{user_input}\\n[SEP] {output}'''\n",
    "    })\n",
    "\n",
    "json_string = json.dumps(finetuned_data, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Write the JSON string to a file\n",
    "with open('/workspace/data/finetuning/dataset/sqlize-finetuned-dataset.json', 'w') as file:\n",
    "    file.write(json_string)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
